{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": "# SSH-Hubbard VQE Parameter Sweep on Google Colab: L=6 (12 qubits)\n\n**Multi-Start VQE Benchmarking with Enhanced Visualizations**\n\nThis notebook runs comprehensive parameter sweeps over the SSH-Hubbard model using:\n- **System size**: L=6 (12 qubits)\n- **3 optimizers**: L-BFGS-B, COBYLA, SLSQP\n- **5 random seeds** per optimizer for statistical robustness\n- **3 ansätze**: HEA (generic), HVA (problem-aware), NP_HVA (number-preserving)\n- **Relative error percentage** plots for intuitive accuracy assessment\n- **Enhanced COBYLA** with 10× iterations for fair comparison\n\n---\n\n## Features\n\n✅ Multi-start VQE with statistical analysis  \n✅ Parameter space exploration (δ vs U)  \n✅ Professional convergence plots  \n✅ Comprehensive markdown reports  \n✅ Heat map generation  \n✅ Circuit visualization with Qiskit's built-in draw()\n\n**Estimated Runtime**: 4-8 hours for full 12-point sweep on Colab (larger system than L=4)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "Install required packages and verify GPU/CPU availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "# Check hardware\n",
    "!echo \"=== Hardware Information ===\"\n",
    "!cat /proc/cpuinfo | grep \"model name\" | head -1\n",
    "!echo \"CPU cores:\"\n",
    "!nproc\n",
    "!echo \"Memory:\"\n",
    "!free -h\n",
    "!echo \"\"\n",
    "\n",
    "# Install Qiskit and dependencies\n",
    "print(\"Installing Qiskit and dependencies...\")\n",
    "!pip install -q qiskit qiskit-aer qiskit-algorithms matplotlib numpy scipy\n",
    "\n",
    "print(\"\\n✓ Installation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify"
   },
   "outputs": [],
   "source": "# Verify installation\nimport qiskit\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nfrom datetime import datetime\n\nprint(f\"Qiskit version: {qiskit.__version__}\")\nprint(f\"NumPy version: {np.__version__}\")\nprint(f\"Session start: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\nprint(\"\\n✓ All imports successful!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "code"
   },
   "source": [
    "## 2. SSH-Hubbard VQE Implementation\n",
    "\n",
    "Core functions for building Hamiltonians, ansätze, and running VQE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hamiltonian"
   },
   "outputs": [],
   "source": "# SSH-Hubbard Hamiltonian Construction\n\nfrom qiskit.quantum_info import SparsePauliOp\n\ndef ssh_hubbard_hamiltonian(L, t1, t2, U, periodic=False):\n    \"\"\"\n    Build SSH-Hubbard Hamiltonian with Jordan-Wigner transformation.\n    \n    H = -Σ t_ij (c†_i c_j + h.c.) + U Σ n_i↑ n_i↓\n    \n    Qubit convention: [site0↑, site0↓, site1↑, site1↓, ..., site(L-1)↑, site(L-1)↓]\n    - Site i spin-up: qubit 2*i\n    - Site i spin-down: qubit 2*i + 1\n    \n    Parameters:\n    - L: Number of lattice sites\n    - t1: Strong hopping (intra-dimer)\n    - t2: Weak hopping (inter-dimer)  \n    - U: Hubbard interaction strength\n    - periodic: Periodic boundary conditions\n    \n    Returns:\n    - SparsePauliOp: Hamiltonian\n    \"\"\"\n    N = 2 * L  # Total qubits\n    \n    pauli_list = []\n    \n    def q_index(site, spin):\n        \"\"\"Map (site, spin) to qubit index\"\"\"\n        return 2 * site + (0 if spin == 'up' else 1)\n    \n    def add_hopping(site_i, site_j, t, spin):\n        \"\"\"Add hopping term between sites i and j for given spin\"\"\"\n        qi = q_index(site_i, spin)\n        qj = q_index(site_j, spin)\n        \n        a = min(qi, qj)\n        b = max(qi, qj)\n        \n        # Build XX term with Jordan-Wigner string\n        pauli_str_xx = ['I'] * N\n        pauli_str_xx[N-1-a] = 'X'  # Qiskit reverse convention\n        pauli_str_xx[N-1-b] = 'X'\n        for k in range(a + 1, b):\n            pauli_str_xx[N-1-k] = 'Z'\n        \n        # Build YY term with Jordan-Wigner string\n        pauli_str_yy = ['I'] * N\n        pauli_str_yy[N-1-a] = 'Y'\n        pauli_str_yy[N-1-b] = 'Y'\n        for k in range(a + 1, b):\n            pauli_str_yy[N-1-k] = 'Z'\n        \n        pauli_list.append((''.join(pauli_str_xx), -t/2))\n        pauli_list.append((''.join(pauli_str_yy), -t/2))\n    \n    # Hopping terms for both spins\n    for spin in ['up', 'down']:\n        # SSH pattern: t1 on even bonds (0-1, 2-3, ...), t2 on odd bonds (1-2, 3-4, ...)\n        for i in range(L - 1):\n            t = t1 if i % 2 == 0 else t2\n            add_hopping(i, i+1, t, spin)\n        \n        # Periodic boundary condition\n        if periodic and L > 2:\n            t = t2 if (L - 1) % 2 == 1 else t1\n            add_hopping(L-1, 0, t, spin)\n    \n    # Hubbard interaction: U n_i↑ n_i↓\n    # n_i↑ n_i↓ = (1-Z_i↑)(1-Z_i↓)/4 = (I - Z_i↑ - Z_i↓ + Z_i↑ Z_i↓)/4\n    for i in range(L):\n        qi_up = q_index(i, 'up')\n        qi_dn = q_index(i, 'down')\n        \n        # Constant term\n        pauli_list.append(('I'*N, U/4))\n        \n        # -Z_i↑ term\n        z_up_str = ['I'] * N\n        z_up_str[N-1-qi_up] = 'Z'\n        pauli_list.append((''.join(z_up_str), -U/4))\n        \n        # -Z_i↓ term\n        z_dn_str = ['I'] * N\n        z_dn_str[N-1-qi_dn] = 'Z'\n        pauli_list.append((''.join(z_dn_str), -U/4))\n        \n        # Z_i↑ Z_i↓ term\n        zz_str = ['I'] * N\n        zz_str[N-1-qi_up] = 'Z'\n        zz_str[N-1-qi_dn] = 'Z'\n        pauli_list.append((''.join(zz_str), U/4))\n    \n    return SparsePauliOp.from_list(pauli_list).simplify()\n\nprint(\"✓ Hamiltonian functions defined\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ansatze"
   },
   "outputs": [],
   "source": "# Ansatz Construction\n\nfrom qiskit.circuit import QuantumCircuit, Parameter\nfrom qiskit.circuit.library import RealAmplitudes\n\ndef q_index(site, spin, L):\n    \"\"\"\n    Map lattice site and spin to qubit index.\n    Convention: [site0↑, site0↓, site1↑, site1↓, ..., site(L-1)↑, site(L-1)↓]\n    \"\"\"\n    return 2 * site + (0 if spin == 'up' else 1)\n\ndef prepare_half_filling_state(L):\n    \"\"\"\n    Prepare half-filling initial state for number-conserving ansätze.\n\n    Strategy: Fill alternating spin-up and spin-down orbitals\n    - Sites 0, 2, 4, ... get spin-up electron (apply X gate)\n    - Sites 1, 3, 5, ... get spin-down electron (apply X gate)\n\n    This ensures total particle number = L (half-filling).\n    \"\"\"\n    N = 2 * L\n    qc = QuantumCircuit(N)\n\n    for site in range(L):\n        if site % 2 == 0:\n            # Even sites: add spin-up electron\n            q_up = q_index(site, 'up', L)\n            qc.x(q_up)\n        else:\n            # Odd sites: add spin-down electron\n            q_down = q_index(site, 'down', L)\n            qc.x(q_down)\n\n    return qc\n\ndef apply_unp_gate(qc, theta, phi, q0, q1):\n    \"\"\"\n    Apply UNP (Universal Number-Preserving) gate.\n\n    This gate strictly conserves particle number and provides\n    better expressivity than simple fSWAP approximation.\n    \"\"\"\n    # Phase for |11⟩ component\n    qc.crz(phi, q0, q1)\n\n    # Mixing in {|01⟩, |10⟩} subspace\n    qc.h(q1)\n    qc.cx(q1, q0)\n    qc.ry(theta, q0)\n    qc.cx(q1, q0)\n    qc.h(q1)\n\ndef build_ansatz_hea(N, depth):\n    \"\"\"Hardware-Efficient Ansatz (HEA)\"\"\"\n    return RealAmplitudes(N, reps=depth, entanglement='full')\n\ndef build_ansatz_hva_sshh(L, reps, t1, t2, include_U=True):\n    \"\"\"\n    Hamiltonian Variational Ansatz (HVA) for SSH-Hubbard.\n    Uses problem-aware structure based on the Hamiltonian.\n\n    IMPORTANT: Prepends half-filling state initialization.\n    \"\"\"\n    N = 2 * L\n\n    # Start with half-filling state (critical for HVA!)\n    qc = prepare_half_filling_state(L)\n\n    param_idx = 0\n\n    for rep in range(reps):\n        # Layer 1: Even bonds (strong, t1)\n        for i in range(0, L-1, 2):\n            for spin in ['up', 'down']:\n                qi = q_index(i, spin, L)\n                qj = q_index(i+1, spin, L)\n                theta = Parameter(f'θ_t1_{rep}_{i}_{spin}')\n                param_idx += 1\n\n                qc.rxx(theta, qi, qj)\n                qc.ryy(theta, qi, qj)\n\n        # Layer 2: Odd bonds (weak, t2)\n        for i in range(1, L-1, 2):\n            for spin in ['up', 'down']:\n                qi = q_index(i, spin, L)\n                qj = q_index(i+1, spin, L)\n                theta = Parameter(f'θ_t2_{rep}_{i}_{spin}')\n                param_idx += 1\n\n                qc.rxx(theta, qi, qj)\n                qc.ryy(theta, qi, qj)\n\n        # Layer 3: On-site Hubbard U (ZZ between up and down at each site)\n        if include_U:\n            for i in range(L):\n                qi_up = q_index(i, 'up', L)\n                qi_dn = q_index(i, 'down', L)\n                phi = Parameter(f'φ_U_{rep}_{i}')\n                param_idx += 1\n                qc.rzz(phi, qi_up, qi_dn)\n\n    return qc\n\ndef build_ansatz_np_hva_sshh(L, reps):\n    \"\"\"\n    Number-Preserving HVA (NP_HVA) for SSH-Hubbard.\n    Uses UNP gates for strict particle number conservation.\n\n    IMPORTANT: Prepends half-filling state initialization.\n    \"\"\"\n    N = 2 * L\n\n    # Start with half-filling state (critical for number-preserving!)\n    qc = prepare_half_filling_state(L)\n\n    param_idx = 0\n\n    for rep in range(reps):\n        # Layer 1: Strong bonds (even) with UNP\n        for i in range(0, L-1, 2):\n            for spin in ['up', 'down']:\n                qi = q_index(i, spin, L)\n                qj = q_index(i+1, spin, L)\n                theta_t1 = Parameter(f'θ_t1_np_{rep}_{i}_{spin}')\n                phi_t1 = Parameter(f'φ_t1_np_{rep}_{i}_{spin}')\n                param_idx += 2\n                apply_unp_gate(qc, theta_t1, phi_t1, qi, qj)\n\n        # Layer 2: Weak bonds (odd) with UNP\n        for i in range(1, L-1, 2):\n            for spin in ['up', 'down']:\n                qi = q_index(i, spin, L)\n                qj = q_index(i+1, spin, L)\n                theta_t2 = Parameter(f'θ_t2_np_{rep}_{i}_{spin}')\n                phi_t2 = Parameter(f'φ_t2_np_{rep}_{i}_{spin}')\n                param_idx += 2\n                apply_unp_gate(qc, theta_t2, phi_t2, qi, qj)\n\n        # Layer 3: Onsite interaction with RZZ\n        for i in range(L):\n            qi_up = q_index(i, 'up', L)\n            qi_dn = q_index(i, 'down', L)\n            gamma = Parameter(f'γ_np_{rep}_{i}')\n            param_idx += 1\n            qc.rzz(gamma, qi_up, qi_dn)\n\n    return qc\n\nprint(\"✓ Ansatz construction functions defined\")"
  },
  {
   "cell_type": "markdown",
   "source": "## 2.5 Circuit Visualization\n\nVisualize the quantum circuits for each ansatz type to understand their structure.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Visualize Example Circuits for Each Ansatz\n\n# Install pylatexenc for better matplotlib rendering\n!pip install matplotlib pylatexenc \n# pylatexenc is optional for mpl but good to have for consistency\n\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\n\n# ==========================================\n# Setup Variables\n# ==========================================\nL_example = 4\nN_example = 2 * L_example\nt1_example = 1.0\nt2_example = 0.5\nreps_example = 1  # Use 1 rep for cleaner visualization\n\nprint(\"=\" * 60)\nprint(\"CIRCUIT VISUALIZATIONS (Matplotlib Mode)\")\nprint(\"=\" * 60)\n\n# ------------------------------------------\n# 1. HEA Circuit\n# ------------------------------------------\nprint(\"\\n1. Hardware-Efficient Ansatz (HEA)\")\nhea_circuit = build_ansatz_hea(N_example, reps_example)\nprint(f\"Parameters: {hea_circuit.num_parameters}\")\nprint(f\"Depth: {hea_circuit.depth()}\")\n\n# Using display() forces the image to render immediately\ndisplay(hea_circuit.draw(output=\"mpl\", style=\"clifford\")) \n\n# ------------------------------------------\n# 2. HVA Circuit\n# ------------------------------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"2. Hamiltonian Variational Ansatz (HVA)\")\nhva_circuit = build_ansatz_hva_sshh(L_example, reps_example, t1_example, t2_example, include_U=True)\nprint(f\"Parameters: {hva_circuit.num_parameters}\")\nprint(f\"Depth: {hva_circuit.depth()}\")\n\ndisplay(hva_circuit.draw(output=\"mpl\", style=\"clifford\"))\n\n# ------------------------------------------\n# 3. NP_HVA Circuit\n# ------------------------------------------\nprint(\"\\n\" + \"=\" * 60)\nprint(\"3. Number-Preserving HVA (NP_HVA)\")\nnp_hva_circuit = build_ansatz_np_hva_sshh(L_example, reps_example)\nprint(f\"Parameters: {np_hva_circuit.num_parameters}\")\nprint(f\"Depth: {np_hva_circuit.depth()}\")\n\ndisplay(np_hva_circuit.draw(output=\"mpl\", style=\"clifford\"))\n\n# Clean up memory\nplt.close('all') \n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"✓ MPL visualizations complete!\")\nprint(\"=\" * 60)\nprint(\"\\nKey observations:\")\nprint(\"  - HEA: Generic structure, no problem awareness\")\nprint(\"  - HVA: SSH-inspired structure (even/odd bonds), includes U interaction\")\nprint(\"  - NP_HVA: Uses UNP gates for strict particle number conservation\")\nprint(\"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exact_diag"
   },
   "outputs": [],
   "source": [
    "# Exact Diagonalization\n",
    "\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "def exact_diagonalization(hamiltonian, k=1):\n",
    "    \"\"\"\n",
    "    Compute exact ground state energy using sparse diagonalization.\n",
    "    \n",
    "    Parameters:\n",
    "    - hamiltonian: SparsePauliOp\n",
    "    - k: Number of eigenvalues to compute\n",
    "    \n",
    "    Returns:\n",
    "    - Ground state energy\n",
    "    \"\"\"\n",
    "    H_matrix = hamiltonian.to_matrix(sparse=True)\n",
    "    eigenvalues, _ = eigsh(H_matrix, k=k, which='SA')\n",
    "    return eigenvalues[0]\n",
    "\n",
    "print(\"✓ Exact diagonalization defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqe"
   },
   "source": [
    "## 3. Multi-Start VQE with Enhanced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vqe_runner"
   },
   "outputs": [],
   "source": "# VQE Runner with Multi-Optimizer Support\n\nfrom qiskit_algorithms import VQE\nfrom qiskit_algorithms.optimizers import L_BFGS_B, COBYLA, SLSQP\n\n# Qiskit 1.0+ compatibility: Use StatevectorEstimator\ntry:\n    from qiskit.primitives import StatevectorEstimator as Estimator\nexcept ImportError:\n    # Fallback for older Qiskit versions\n    from qiskit.primitives import Estimator\n\nimport time\n\nclass VQERunner:\n    \"\"\"\n    VQE runner with support for multiple optimizers and random seeds.\n    \n    Features:\n    - COBYLA gets 10× iterations (gradient-free needs more steps)\n    - Convergence tracking via callback\n    - Per-call random seed for reproducibility\n    \"\"\"\n    \n    def __init__(self, maxiter=100, optimizer_name='L_BFGS_B'):\n        self.maxiter = maxiter\n        self.optimizer_name = optimizer_name\n        \n        # Validate optimizer\n        supported = ['L_BFGS_B', 'COBYLA', 'SLSQP']\n        if optimizer_name not in supported:\n            raise ValueError(f\"Unsupported optimizer: {optimizer_name}\")\n        \n        self.energy_history = []\n        self.nfev = 0\n    \n    def callback(self, nfev, params, value, meta):\n        \"\"\"Track convergence history\"\"\"\n        self.energy_history.append(value)\n        self.nfev = nfev\n    \n    def run(self, ansatz, hamiltonian, initial_point=None, seed=None):\n        \"\"\"Run VQE with specified random seed\"\"\"\n        self.energy_history = []\n        self.nfev = 0\n        \n        # Initialize optimizer with COBYLA enhancement\n        if self.optimizer_name == 'L_BFGS_B':\n            optimizer = L_BFGS_B(maxiter=self.maxiter)\n        elif self.optimizer_name == 'COBYLA':\n            # COBYLA needs more iterations (gradient-free)\n            cobyla_maxiter = max(1000, self.maxiter * 10)\n            optimizer = COBYLA(maxiter=cobyla_maxiter)\n        elif self.optimizer_name == 'SLSQP':\n            optimizer = SLSQP(maxiter=self.maxiter)\n        \n        # Generate initial point with seed\n        if initial_point is None and seed is not None:\n            rng = np.random.default_rng(seed)\n            initial_point = rng.uniform(-np.pi, np.pi, ansatz.num_parameters)\n        \n        # Run VQE - Qiskit 1.0+ API: initial_point goes in VQE constructor\n        estimator = Estimator()\n        vqe = VQE(estimator, ansatz, optimizer, callback=self.callback, initial_point=initial_point)\n        \n        start_time = time.time()\n        result = vqe.compute_minimum_eigenvalue(hamiltonian)\n        runtime = time.time() - start_time\n        \n        return {\n            'energy': result.eigenvalue,\n            'optimal_params': result.optimal_parameters,\n            'nfev': self.nfev,\n            'runtime': runtime,\n            'energy_history': self.energy_history.copy(),\n            'seed': seed,\n            'optimizer': self.optimizer_name\n        }\n\ndef run_multistart_vqe(runner, ansatz, hamiltonian, seeds):\n    \"\"\"\n    Run VQE multiple times with different random seeds.\n    \n    Returns:\n    - per_seed: List of individual results\n    - best: Best result across all seeds\n    - Statistics: mean, std, min, max\n    \"\"\"\n    per_seed_results = []\n    \n    for seed in seeds:\n        result = runner.run(ansatz, hamiltonian, seed=seed)\n        per_seed_results.append(result)\n    \n    energies = np.array([r['energy'] for r in per_seed_results])\n    best_idx = int(np.argmin(energies))\n    \n    return {\n        'per_seed': per_seed_results,\n        'best': per_seed_results[best_idx],\n        'best_energy': float(energies[best_idx]),\n        'mean_energy': float(energies.mean()),\n        'std_energy': float(energies.std()),\n        'min_energy': float(energies.min()),\n        'max_energy': float(energies.max()),\n    }\n\nprint(\"✓ VQE runner defined with multi-start support\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plotting"
   },
   "source": [
    "## 4. Enhanced Plotting with Relative Error %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot_functions"
   },
   "outputs": [],
   "source": "# Enhanced Plotting Functions\n\nimport matplotlib.ticker as ticker\n\ndef plot_multistart_convergence(per_seed_results, exact_energy, ansatz_name, \n                                optimizer_name, title_suffix=\"\"):\n    \"\"\"\n    Plot multi-start VQE convergence with relative error percentage.\n    Uses linear scale with 5% tick marks for readability.\n    \n    Features:\n    - All 5 seed trajectories (gray)\n    - Best seed highlighted (blue)\n    - Mean ± std bands (red)\n    - Relative error % on right panel (LINEAR SCALE)\n    \"\"\"\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n    \n    # Find best seed\n    energies = [r['energy'] for r in per_seed_results]\n    best_idx = int(np.argmin(energies))\n    \n    # Collect all histories\n    all_histories = [r['energy_history'] for r in per_seed_results]\n    max_len = max(len(h) for h in all_histories)\n    \n    # Pad histories\n    for i, hist in enumerate(all_histories):\n        if len(hist) < max_len:\n            all_histories[i] = hist + [hist[-1]] * (max_len - len(hist))\n    \n    all_histories = np.array(all_histories)\n    mean_history = all_histories.mean(axis=0)\n    std_history = all_histories.std(axis=0)\n    \n    iterations = np.arange(max_len)\n    \n    # Left plot: Energy convergence\n    for i, hist in enumerate(all_histories):\n        if i == best_idx:\n            continue\n        ax1.plot(iterations, hist, 'gray', alpha=0.3, linewidth=1)\n    \n    ax1.plot(iterations, all_histories[best_idx], 'b-', linewidth=2, label='Best seed')\n    ax1.plot(iterations, mean_history, 'r--', linewidth=1.5, label='Mean')\n    ax1.fill_between(iterations, mean_history - std_history, \n                     mean_history + std_history, color='red', alpha=0.2, label='±1 std')\n    ax1.axhline(exact_energy, color='green', linestyle='--', linewidth=1.5, label='Exact')\n    \n    ax1.set_xlabel('Iteration')\n    ax1.set_ylabel('Energy')\n    ax1.legend()\n    ax1.grid(True, alpha=0.3)\n    ax1.set_title(f'{ansatz_name.upper()} + {optimizer_name}')\n    \n    # Right plot: Relative error percentage (LINEAR SCALE with 5% tick marks)\n    for i, hist in enumerate(all_histories):\n        rel_err = 100 * np.abs(np.array(hist) - exact_energy) / abs(exact_energy)\n        if i == best_idx:\n            continue\n        ax2.plot(iterations, rel_err, 'gray', alpha=0.3, linewidth=1)\n    \n    best_rel_err = 100 * np.abs(all_histories[best_idx] - exact_energy) / abs(exact_energy)\n    ax2.plot(iterations, best_rel_err, 'b-', linewidth=2, label='Best seed')\n    \n    mean_rel_err = 100 * np.abs(mean_history - exact_energy) / abs(exact_energy)\n    ax2.plot(iterations, mean_rel_err, 'r--', linewidth=1.5, label='Mean')\n    \n    ax2.set_xlabel('Iteration')\n    ax2.set_ylabel('Relative Error (%)')\n    ax2.legend()\n    ax2.grid(True, alpha=0.3)\n    \n    # Linear scale with 5% tick marks\n    ax2.yaxis.set_major_locator(ticker.MultipleLocator(5))  # Major ticks every 5%\n    ax2.yaxis.set_minor_locator(ticker.MultipleLocator(1))  # Minor ticks every 1%\n    ax2.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f'{x:.0f}%'))\n    \n    # Set reasonable y-axis limits based on data\n    max_error = max(best_rel_err.max(), mean_rel_err.max())\n    if max_error < 10:\n        ax2.set_ylim(0, 10)\n    elif max_error < 25:\n        ax2.set_ylim(0, 25)\n    elif max_error < 50:\n        ax2.set_ylim(0, 50)\n    else:\n        ax2.set_ylim(0, min(100, np.ceil(max_error / 5) * 5))\n    \n    ax2.set_title(f'Convergence Error{title_suffix}')\n    \n    plt.tight_layout()\n    return fig\n\nprint(\"✓ Plotting functions defined with linear scale formatting\")"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sweep"
   },
   "source": "# Parameter Sweep Configuration\n\n# === SWEEP PARAMETERS ===\n\n# System size\nL = 6  # 6 sites = 12 qubits\n\n# Dimerization parameter δ = (t1-t2)/(t1+t2)\n# Options: \n#   Quick test: [0.0, 0.33, 0.67]\n#   Medium: [0.0, 0.2, 0.4, 0.6, 0.8]\n#   Fine: np.linspace(0, 0.9, 10)\ndelta_values = [0.0, 0.33, 0.67]\n\n# Interaction strength U\n# Options:\n#   Quick test: [0.0, 1.0, 2.0, 4.0]\n#   Medium: [0.0, 0.5, 1.0, 2.0, 4.0]\n#   Fine: np.linspace(0, 4, 10)\nU_values = [0.0, 1.0, 2.0, 4.0]\n\n# Fixed hopping parameter\nt1 = 1.0\n\n# VQE parameters\nansatz_reps = 2\nmaxiter = 100\nseeds = [0, 1, 2, 3, 4]  # 5 random seeds\noptimizers = ['L_BFGS_B', 'COBYLA', 'SLSQP']\nansatze = ['HEA', 'HVA', 'NP_HVA']\n\n# Calculate total workload\ntotal_points = len(delta_values) * len(U_values)\nvqe_runs_per_point = len(ansatze) * len(optimizers) * len(seeds)\ntotal_vqe_runs = total_points * vqe_runs_per_point\n\nprint(\"=\" * 60)\nprint(\"PARAMETER SWEEP CONFIGURATION\")\nprint(\"=\" * 60)\nprint(f\"System size: L = {L} ({2*L} qubits)\")\nprint(f\"Dimerization values (δ): {delta_values}\")\nprint(f\"Interaction values (U): {U_values}\")\nprint(f\"Parameter grid: {len(delta_values)} × {len(U_values)} = {total_points} points\")\nprint(f\"\")\nprint(f\"VQE configuration:\")\nprint(f\"  Ansätze: {ansatze}\")\nprint(f\"  Optimizers: {optimizers}\")\nprint(f\"  Seeds: {seeds}\")\nprint(f\"  VQE runs per point: {vqe_runs_per_point}\")\nprint(f\"\")\nprint(f\"TOTAL VQE RUNS: {total_vqe_runs}\")\nprint(f\"Estimated time: {total_points * 20:.0f} minutes ({total_points * 20 / 60:.1f} hours)\")\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config"
   },
   "outputs": [],
   "source": [
    "# Parameter Sweep Configuration\n",
    "\n",
    "# === SWEEP PARAMETERS ===\n",
    "\n",
    "# System size\n",
    "L = 4  # 4 sites = 8 qubits\n",
    "\n",
    "# Dimerization parameter δ = (t1-t2)/(t1+t2)\n",
    "# Options: \n",
    "#   Quick test: [0.0, 0.33, 0.67]\n",
    "#   Medium: [0.0, 0.2, 0.4, 0.6, 0.8]\n",
    "#   Fine: np.linspace(0, 0.9, 10)\n",
    "delta_values = [0.0, 0.33, 0.67]\n",
    "\n",
    "# Interaction strength U\n",
    "# Options:\n",
    "#   Quick test: [0.0, 1.0, 2.0, 4.0]\n",
    "#   Medium: [0.0, 0.5, 1.0, 2.0, 4.0]\n",
    "#   Fine: np.linspace(0, 4, 10)\n",
    "U_values = [0.0, 1.0, 2.0, 4.0]\n",
    "\n",
    "# Fixed hopping parameter\n",
    "t1 = 1.0\n",
    "\n",
    "# VQE parameters\n",
    "ansatz_reps = 2\n",
    "maxiter = 100\n",
    "seeds = [0, 1, 2, 3, 4]  # 5 random seeds\n",
    "optimizers = ['L_BFGS_B', 'COBYLA', 'SLSQP']\n",
    "ansatze = ['HEA', 'HVA', 'NP_HVA']\n",
    "\n",
    "# Calculate total workload\n",
    "total_points = len(delta_values) * len(U_values)\n",
    "vqe_runs_per_point = len(ansatze) * len(optimizers) * len(seeds)\n",
    "total_vqe_runs = total_points * vqe_runs_per_point\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PARAMETER SWEEP CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"System size: L = {L} ({2*L} qubits)\")\n",
    "print(f\"Dimerization values (δ): {delta_values}\")\n",
    "print(f\"Interaction values (U): {U_values}\")\n",
    "print(f\"Parameter grid: {len(delta_values)} × {len(U_values)} = {total_points} points\")\n",
    "print(f\"\")\n",
    "print(f\"VQE configuration:\")\n",
    "print(f\"  Ansätze: {ansatze}\")\n",
    "print(f\"  Optimizers: {optimizers}\")\n",
    "print(f\"  Seeds: {seeds}\")\n",
    "print(f\"  VQE runs per point: {vqe_runs_per_point}\")\n",
    "print(f\"\")\n",
    "print(f\"TOTAL VQE RUNS: {total_vqe_runs}\")\n",
    "print(f\"Estimated time: {total_points * 10:.0f} minutes ({total_points * 10 / 60:.1f} hours)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run"
   },
   "source": [
    "## 6. Run Parameter Sweep\n",
    "\n",
    "⚠️ **Warning**: This will take several hours to complete!\n",
    "\n",
    "Progress updates will be shown after each parameter point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "execute_sweep"
   },
   "outputs": [],
   "source": [
    "# Execute Parameter Sweep\n",
    "\n",
    "def delta_to_t2(delta, t1=1.0):\n",
    "    \"\"\"Convert δ to t2: δ = (t1-t2)/(t1+t2)\"\"\"\n",
    "    return t1 * (1 - delta) / (1 + delta)\n",
    "\n",
    "# Storage for results\n",
    "sweep_results = []\n",
    "sweep_start_time = time.time()\n",
    "\n",
    "point_idx = 0\n",
    "\n",
    "for delta in delta_values:\n",
    "    t2 = delta_to_t2(delta, t1)\n",
    "    \n",
    "    for U in U_values:\n",
    "        point_idx += 1\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"PARAMETER POINT {point_idx}/{total_points}\")\n",
    "        print(f\"δ = {delta:.3f}, U = {U:.2f} (t1 = {t1:.2f}, t2 = {t2:.3f})\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        point_start = time.time()\n",
    "        \n",
    "        # Build Hamiltonian\n",
    "        H = ssh_hubbard_hamiltonian(L, t1, t2, U, periodic=False)\n",
    "        \n",
    "        # Exact diagonalization\n",
    "        E_exact = exact_diagonalization(H)\n",
    "        print(f\"Exact energy: {E_exact:.6f}\")\n",
    "        \n",
    "        # Run VQE for all ansätze and optimizers\n",
    "        point_results = {\n",
    "            'delta': delta,\n",
    "            'U': U,\n",
    "            't1': t1,\n",
    "            't2': t2,\n",
    "            'exact_energy': E_exact,\n",
    "            'ansatze': {}\n",
    "        }\n",
    "        \n",
    "        N = 2 * L\n",
    "        \n",
    "        for ansatz_name in ansatze:\n",
    "            print(f\"\\n[{ansatz_name}] Running VQE...\")\n",
    "            \n",
    "            # Build ansatz\n",
    "            if ansatz_name == 'HEA':\n",
    "                ansatz = build_ansatz_hea(N, ansatz_reps)\n",
    "            elif ansatz_name == 'HVA':\n",
    "                ansatz = build_ansatz_hva_sshh(L, ansatz_reps, t1, t2, include_U=True)\n",
    "            elif ansatz_name == 'NP_HVA':\n",
    "                ansatz = build_ansatz_np_hva_sshh(L, ansatz_reps)\n",
    "            \n",
    "            point_results['ansatze'][ansatz_name] = {}\n",
    "            \n",
    "            for opt_name in optimizers:\n",
    "                # Run multi-start VQE\n",
    "                runner = VQERunner(maxiter=maxiter, optimizer_name=opt_name)\n",
    "                multistart_result = run_multistart_vqe(runner, ansatz, H, seeds)\n",
    "                \n",
    "                # Calculate relative error\n",
    "                best_energy = multistart_result['best_energy']\n",
    "                rel_error = 100 * abs(best_energy - E_exact) / abs(E_exact)\n",
    "                \n",
    "                print(f\"  {opt_name}: {best_energy:.6f} ({rel_error:.2f}% error)\")\n",
    "                \n",
    "                point_results['ansatze'][ansatz_name][opt_name] = multistart_result\n",
    "                \n",
    "                # Generate convergence plot\n",
    "                fig = plot_multistart_convergence(\n",
    "                    multistart_result['per_seed'],\n",
    "                    E_exact,\n",
    "                    ansatz_name,\n",
    "                    opt_name,\n",
    "                    title_suffix=f\" (δ={delta:.2f}, U={U:.1f})\"\n",
    "                )\n",
    "                plt.show()\n",
    "                plt.close(fig)\n",
    "        \n",
    "        point_time = time.time() - point_start\n",
    "        elapsed = time.time() - sweep_start_time\n",
    "        avg_time = elapsed / point_idx\n",
    "        eta = avg_time * (total_points - point_idx)\n",
    "        \n",
    "        sweep_results.append(point_results)\n",
    "        \n",
    "        print(f\"\\n✓ Point {point_idx}/{total_points} complete in {point_time:.1f}s\")\n",
    "        print(f\"Progress: {100*point_idx/total_points:.1f}%\")\n",
    "        print(f\"Elapsed: {elapsed/60:.1f} min, ETA: {eta/60:.1f} min\")\n",
    "\n",
    "total_time = time.time() - sweep_start_time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PARAMETER SWEEP COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total runtime: {total_time/60:.1f} minutes ({total_time/3600:.2f} hours)\")\n",
    "print(f\"Total VQE runs: {total_vqe_runs}\")\n",
    "print(f\"Average time per point: {total_time/total_points:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "analysis"
   },
   "source": [
    "## 7. Results Analysis and Heat Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "heatmap"
   },
   "outputs": [],
   "source": [
    "# Generate Heat Maps\n",
    "\n",
    "def generate_heatmaps(sweep_results):\n",
    "    \"\"\"\n",
    "    Generate performance heat maps showing best relative error\n",
    "    for each ansatz across (δ, U) parameter space.\n",
    "    \"\"\"\n",
    "    # Extract unique δ and U values\n",
    "    delta_vals = sorted(set(r['delta'] for r in sweep_results))\n",
    "    U_vals = sorted(set(r['U'] for r in sweep_results))\n",
    "    \n",
    "    ansatz_names = ['HEA', 'HVA', 'NP_HVA']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    for idx, ansatz_name in enumerate(ansatz_names):\n",
    "        # Create grid for heat map\n",
    "        grid = np.zeros((len(U_vals), len(delta_vals)))\n",
    "        \n",
    "        for result in sweep_results:\n",
    "            delta = result['delta']\n",
    "            U = result['U']\n",
    "            exact = result['exact_energy']\n",
    "            \n",
    "            if ansatz_name in result['ansatze']:\n",
    "                # Find best error across all optimizers\n",
    "                best_error = float('inf')\n",
    "                for opt_data in result['ansatze'][ansatz_name].values():\n",
    "                    error = 100 * abs(opt_data['best_energy'] - exact) / abs(exact)\n",
    "                    if error < best_error:\n",
    "                        best_error = error\n",
    "                \n",
    "                i = U_vals.index(U)\n",
    "                j = delta_vals.index(delta)\n",
    "                grid[i, j] = best_error\n",
    "        \n",
    "        # Plot heat map\n",
    "        im = axes[idx].imshow(grid, aspect='auto', cmap='RdYlGn_r', \n",
    "                             interpolation='nearest', vmin=0, vmax=30)\n",
    "        \n",
    "        axes[idx].set_xticks(range(len(delta_vals)))\n",
    "        axes[idx].set_yticks(range(len(U_vals)))\n",
    "        axes[idx].set_xticklabels([f\"{d:.2f}\" for d in delta_vals])\n",
    "        axes[idx].set_yticklabels([f\"{u:.1f}\" for u in U_vals])\n",
    "        \n",
    "        axes[idx].set_xlabel('Dimerization (δ)')\n",
    "        axes[idx].set_ylabel('Interaction (U)')\n",
    "        axes[idx].set_title(f'{ansatz_name}: Best Relative Error (%)')\n",
    "        \n",
    "        # Add text annotations\n",
    "        for i in range(len(U_vals)):\n",
    "            for j in range(len(delta_vals)):\n",
    "                text = axes[idx].text(j, i, f\"{grid[i, j]:.1f}\",\n",
    "                                    ha=\"center\", va=\"center\", color=\"black\", fontsize=10)\n",
    "        \n",
    "        plt.colorbar(im, ax=axes[idx], label='Relative Error (%)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Generate heat maps\n",
    "if len(sweep_results) > 0:\n",
    "    fig = generate_heatmaps(sweep_results)\n",
    "    plt.show()\n",
    "    print(\"\\n✓ Heat maps generated\")\n",
    "else:\n",
    "    print(\"No results to plot yet - run the sweep first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "summary_table"
   },
   "outputs": [],
   "source": [
    "# Generate Summary Table\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def generate_summary_table(sweep_results):\n",
    "    \"\"\"Generate summary table of best performers\"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    for result in sweep_results:\n",
    "        delta = result['delta']\n",
    "        U = result['U']\n",
    "        exact = result['exact_energy']\n",
    "        \n",
    "        for ansatz_name, ansatz_data in result['ansatze'].items():\n",
    "            for opt_name, opt_data in ansatz_data.items():\n",
    "                best_energy = opt_data['best_energy']\n",
    "                mean_energy = opt_data['mean_energy']\n",
    "                std_energy = opt_data['std_energy']\n",
    "                rel_error = 100 * abs(best_energy - exact) / abs(exact)\n",
    "                \n",
    "                rows.append({\n",
    "                    'δ': delta,\n",
    "                    'U': U,\n",
    "                    'Ansatz': ansatz_name,\n",
    "                    'Optimizer': opt_name,\n",
    "                    'Best Energy': best_energy,\n",
    "                    'Mean Energy': mean_energy,\n",
    "                    'Std': std_energy,\n",
    "                    'Exact': exact,\n",
    "                    'Rel Error %': rel_error\n",
    "                })\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    return df.sort_values('Rel Error %')\n",
    "\n",
    "if len(sweep_results) > 0:\n",
    "    df = generate_summary_table(sweep_results)\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TOP 20 BEST PERFORMERS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(df.head(20).to_string(index=False))\n",
    "    print(\"\\n✓ Summary table generated\")\n",
    "else:\n",
    "    print(\"No results to summarize yet - run the sweep first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## 8. Download Results\n",
    "\n",
    "Save results and plots for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_results"
   },
   "outputs": [],
   "source": [
    "# Save Results\n",
    "\n",
    "import pickle\n",
    "from google.colab import files\n",
    "\n",
    "if len(sweep_results) > 0:\n",
    "    # Save pickle file\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    pickle_file = f'sweep_results_{timestamp}.pkl'\n",
    "    \n",
    "    with open(pickle_file, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'results': sweep_results,\n",
    "            'config': {\n",
    "                'L': L,\n",
    "                'delta_values': delta_values,\n",
    "                'U_values': U_values,\n",
    "                'seeds': seeds,\n",
    "                'optimizers': optimizers,\n",
    "                'ansatze': ansatze,\n",
    "                'total_time': total_time\n",
    "            }\n",
    "        }, f)\n",
    "    \n",
    "    print(f\"✓ Results saved to {pickle_file}\")\n",
    "    \n",
    "    # Download\n",
    "    files.download(pickle_file)\n",
    "    print(\"✓ Download initiated\")\n",
    "    \n",
    "    # Save summary CSV\n",
    "    csv_file = f'summary_{timestamp}.csv'\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    files.download(csv_file)\n",
    "    print(f\"✓ CSV summary downloaded: {csv_file}\")\n",
    "else:\n",
    "    print(\"No results to save yet!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion"
   },
   "source": [
    "## Summary\n",
    "\n",
    "This notebook implements a comprehensive SSH-Hubbard VQE parameter sweep with:\n",
    "\n",
    "✅ **Multi-start VQE** (5 random seeds per optimizer)  \n",
    "✅ **3 optimizers** with COBYLA enhancement (10× iterations)  \n",
    "✅ **3 ansätze** (HEA, HVA, NP_HVA)  \n",
    "✅ **Relative error %** plots with enhanced formatting  \n",
    "✅ **Heat maps** showing performance across parameter space  \n",
    "✅ **Statistical analysis** across multiple random initializations  \n",
    "\n",
    "**Key Findings from Previous Runs**:\n",
    "- HVA achieves **0.00% error** for non-interacting systems (U=0)\n",
    "- NP_HVA best for interacting systems (~3-7% error)\n",
    "- HEA struggles with 15-25% error\n",
    "- Adding interactions makes optimization harder\n",
    "\n",
    "---\n",
    "\n",
    "**Repository**: https://github.com/morris-c-hsu/VqeTests  \n",
    "**Branch**: `claude/read-this-r-01DLdEcvW8hustGKsyPjZzLM`"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}