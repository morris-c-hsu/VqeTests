{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSH-Hubbard VQE Quick Test Notebook\n",
    "\n",
    "**Minimal test to verify core functionality before full sweep**\n",
    "\n",
    "This notebook runs a **quick test** with:\n",
    "- **2 parameter points**: (δ=0.0, U=0.0) and (δ=0.33, U=1.0)\n",
    "- **2 optimizers**: L-BFGS-B, COBYLA\n",
    "- **2 random seeds** for statistical validation\n",
    "- **2 ansätze**: HVA (problem-aware), NP_HVA (number-preserving)\n",
    "- **50 iterations** (faster convergence)\n",
    "\n",
    "**Total VQE runs**: 16 (vs 540 in full sweep)\n",
    "**Estimated runtime**: 2-3 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Purpose\n",
    "\n",
    "✅ Verify Hamiltonian construction works correctly  \n",
    "✅ Test ansatz building (HVA, NP_HVA)  \n",
    "✅ Validate VQE runner with COBYLA enhancement  \n",
    "✅ Check plotting functions generate correct visualizations  \n",
    "✅ Ensure no import errors or runtime issues  \n",
    "\n",
    "**Use this to validate before running the full sweep on Colab!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check hardware (Colab only)\n",
    "import sys\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    !echo \"=== Hardware Information ===\"\n",
    "    !cat /proc/cpuinfo | grep \"model name\" | head -1\n",
    "    !echo \"CPU cores:\"\n",
    "    !nproc\n",
    "    !echo \"Memory:\"\n",
    "    !free -h\n",
    "    !echo \"\"\n",
    "    \n",
    "    # Install Qiskit and dependencies\n",
    "    print(\"Installing Qiskit and dependencies...\")\n",
    "    !pip install -q qiskit qiskit-aer qiskit-algorithms matplotlib numpy scipy\n",
    "    print(\"\\n✓ Installation complete!\")\n",
    "else:\n",
    "    print(\"Running locally - skipping Colab-specific setup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify installation\n",
    "import qiskit\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"Qiskit version: {qiskit.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Session start: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"\\n✓ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SSH-Hubbard VQE Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSH-Hubbard Hamiltonian Construction\n",
    "\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "\n",
    "def ssh_hubbard_hamiltonian(L, t1, t2, U, periodic=False):\n",
    "    \"\"\"\n",
    "    Build SSH-Hubbard Hamiltonian with Jordan-Wigner transformation.\n",
    "    \n",
    "    H = -Σ t_ij (c†_i c_j + h.c.) + U Σ n_i↑ n_i↓\n",
    "    \n",
    "    Parameters:\n",
    "    - L: Number of lattice sites\n",
    "    - t1: Strong hopping (intra-dimer)\n",
    "    - t2: Weak hopping (inter-dimer)  \n",
    "    - U: Hubbard interaction strength\n",
    "    - periodic: Periodic boundary conditions\n",
    "    \n",
    "    Returns:\n",
    "    - SparsePauliOp: Hamiltonian\n",
    "    \"\"\"\n",
    "    N = 2 * L  # Total qubits (spin up + spin down)\n",
    "    \n",
    "    pauli_list = []\n",
    "    \n",
    "    # Hopping terms (Jordan-Wigner)\n",
    "    def add_hopping(i, j, t, spin_offset=0):\n",
    "        \"\"\"Add hopping term between sites i and j for given spin\"\"\"\n",
    "        qi = i + spin_offset\n",
    "        qj = j + spin_offset\n",
    "        \n",
    "        pauli_str_xx = ['I'] * N\n",
    "        pauli_str_yy = ['I'] * N\n",
    "        \n",
    "        pauli_str_xx[qi] = 'X'\n",
    "        pauli_str_xx[qj] = 'X'\n",
    "        pauli_str_yy[qi] = 'Y'\n",
    "        pauli_str_yy[qj] = 'Y'\n",
    "        \n",
    "        # Add Z string for JW transformation\n",
    "        for k in range(min(qi, qj) + 1, max(qi, qj)):\n",
    "            pauli_str_xx[k] = 'Z'\n",
    "            pauli_str_yy[k] = 'Z'\n",
    "        \n",
    "        pauli_list.append((''.join(reversed(pauli_str_xx)), -t/2))\n",
    "        pauli_list.append((''.join(reversed(pauli_str_yy)), -t/2))\n",
    "    \n",
    "    # Intra-dimer hopping (strong, t1)\n",
    "    for i in range(0, L-1, 2):\n",
    "        add_hopping(i, i+1, t1, spin_offset=0)  # Spin up\n",
    "        add_hopping(i, i+1, t1, spin_offset=L)  # Spin down\n",
    "    \n",
    "    # Inter-dimer hopping (weak, t2)\n",
    "    for i in range(1, L-1, 2):\n",
    "        add_hopping(i, i+1, t2, spin_offset=0)  # Spin up\n",
    "        add_hopping(i, i+1, t2, spin_offset=L)  # Spin down\n",
    "    \n",
    "    # Periodic boundary condition\n",
    "    if periodic and L > 2:\n",
    "        add_hopping(L-1, 0, t2, spin_offset=0)\n",
    "        add_hopping(L-1, 0, t2, spin_offset=L)\n",
    "    \n",
    "    # Hubbard interaction: U n_i↑ n_i↓\n",
    "    for i in range(L):\n",
    "        pauli_str_interaction = ['I'] * N\n",
    "        pauli_str_interaction[i] = 'Z'\n",
    "        pauli_str_interaction[i+L] = 'Z'\n",
    "        \n",
    "        # n_i↑ n_i↓ = (1-Z_i)(1-Z_{i+L})/4\n",
    "        pauli_list.append(('I'*N, U/4))  # Constant term\n",
    "        \n",
    "        zi_str = ['I'] * N\n",
    "        zi_str[i] = 'Z'\n",
    "        pauli_list.append((''.join(reversed(zi_str)), -U/4))\n",
    "        \n",
    "        zi_plus_l_str = ['I'] * N\n",
    "        zi_plus_l_str[i+L] = 'Z'\n",
    "        pauli_list.append((''.join(reversed(zi_plus_l_str)), -U/4))\n",
    "        \n",
    "        pauli_list.append((''.join(reversed(pauli_str_interaction)), U/4))\n",
    "    \n",
    "    return SparsePauliOp.from_list(pauli_list).simplify()\n",
    "\n",
    "print(\"✓ Hamiltonian functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ansatz Construction\n",
    "\n",
    "from qiskit.circuit import QuantumCircuit, Parameter\n",
    "\n",
    "def build_ansatz_hva_sshh(L, reps, t1, t2, include_U=True):\n",
    "    \"\"\"\n",
    "    Hamiltonian Variational Ansatz (HVA) for SSH-Hubbard.\n",
    "    Uses problem-aware structure based on the Hamiltonian.\n",
    "    \"\"\"\n",
    "    N = 2 * L\n",
    "    qc = QuantumCircuit(N)\n",
    "    \n",
    "    param_idx = 0\n",
    "    \n",
    "    for rep in range(reps):\n",
    "        # Hopping layers (XX + YY rotations)\n",
    "        # Intra-dimer\n",
    "        for i in range(0, L-1, 2):\n",
    "            theta = Parameter(f'θ_{param_idx}')\n",
    "            param_idx += 1\n",
    "            # Spin up\n",
    "            qc.rxx(theta, i, i+1)\n",
    "            qc.ryy(theta, i, i+1)\n",
    "            # Spin down\n",
    "            qc.rxx(theta, i+L, i+1+L)\n",
    "            qc.ryy(theta, i+L, i+1+L)\n",
    "        \n",
    "        # Inter-dimer\n",
    "        for i in range(1, L-1, 2):\n",
    "            theta = Parameter(f'θ_{param_idx}')\n",
    "            param_idx += 1\n",
    "            # Spin up\n",
    "            qc.rxx(theta, i, i+1)\n",
    "            qc.ryy(theta, i, i+1)\n",
    "            # Spin down\n",
    "            qc.rxx(theta, i+L, i+1+L)\n",
    "            qc.ryy(theta, i+L, i+1+L)\n",
    "        \n",
    "        # Interaction layer\n",
    "        if include_U:\n",
    "            for i in range(L):\n",
    "                theta = Parameter(f'θ_{param_idx}')\n",
    "                param_idx += 1\n",
    "                qc.rzz(theta, i, i+L)\n",
    "        \n",
    "        # Single-qubit rotations\n",
    "        for i in range(N):\n",
    "            theta = Parameter(f'θ_{param_idx}')\n",
    "            param_idx += 1\n",
    "            qc.rz(theta, i)\n",
    "    \n",
    "    return qc\n",
    "\n",
    "def build_ansatz_np_hva_sshh(L, reps):\n",
    "    \"\"\"\n",
    "    Number-Preserving HVA (NP_HVA) for SSH-Hubbard.\n",
    "    Strictly conserves particle number using fermionic SWAP networks.\n",
    "    \"\"\"\n",
    "    N = 2 * L\n",
    "    qc = QuantumCircuit(N)\n",
    "    \n",
    "    param_idx = 0\n",
    "    \n",
    "    for rep in range(reps):\n",
    "        # Number-preserving hopping (fermionic SWAP)\n",
    "        for i in range(0, L-1, 2):\n",
    "            theta = Parameter(f'θ_{param_idx}')\n",
    "            param_idx += 1\n",
    "            # fSWAP approximation\n",
    "            qc.cx(i, i+1)\n",
    "            qc.ry(theta, i+1)\n",
    "            qc.cx(i, i+1)\n",
    "            \n",
    "            qc.cx(i+L, i+1+L)\n",
    "            qc.ry(theta, i+1+L)\n",
    "            qc.cx(i+L, i+1+L)\n",
    "        \n",
    "        for i in range(1, L-1, 2):\n",
    "            theta = Parameter(f'θ_{param_idx}')\n",
    "            param_idx += 1\n",
    "            qc.cx(i, i+1)\n",
    "            qc.ry(theta, i+1)\n",
    "            qc.cx(i, i+1)\n",
    "            \n",
    "            qc.cx(i+L, i+1+L)\n",
    "            qc.ry(theta, i+1+L)\n",
    "            qc.cx(i+L, i+1+L)\n",
    "        \n",
    "        # Number-preserving interaction\n",
    "        for i in range(L):\n",
    "            theta = Parameter(f'θ_{param_idx}')\n",
    "            param_idx += 1\n",
    "            qc.rzz(theta, i, i+L)\n",
    "    \n",
    "    return qc\n",
    "\n",
    "print(\"✓ Ansatz construction functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exact Diagonalization\n",
    "\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "def exact_diagonalization(hamiltonian, k=1):\n",
    "    \"\"\"\n",
    "    Compute exact ground state energy using sparse diagonalization.\n",
    "    \n",
    "    Parameters:\n",
    "    - hamiltonian: SparsePauliOp\n",
    "    - k: Number of eigenvalues to compute\n",
    "    \n",
    "    Returns:\n",
    "    - Ground state energy\n",
    "    \"\"\"\n",
    "    H_matrix = hamiltonian.to_matrix(sparse=True)\n",
    "    eigenvalues, _ = eigsh(H_matrix, k=k, which='SA')\n",
    "    return eigenvalues[0]\n",
    "\n",
    "print(\"✓ Exact diagonalization defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multi-Start VQE with Enhanced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# VQE Runner with Multi-Optimizer Support\n\nfrom qiskit_algorithms import VQE\nfrom qiskit_algorithms.optimizers import L_BFGS_B, COBYLA\n\n# Qiskit 1.0+ compatibility: Use StatevectorEstimator\ntry:\n    from qiskit.primitives import StatevectorEstimator as Estimator\nexcept ImportError:\n    # Fallback for older Qiskit versions\n    from qiskit.primitives import Estimator\n\nclass VQERunner:\n    \"\"\"\n    VQE runner with support for multiple optimizers and random seeds.\n    \n    Features:\n    - COBYLA gets 10× iterations (gradient-free needs more steps)\n    - Convergence tracking via callback\n    - Per-call random seed for reproducibility\n    \"\"\"\n    \n    def __init__(self, maxiter=50, optimizer_name='L_BFGS_B'):\n        self.maxiter = maxiter\n        self.optimizer_name = optimizer_name\n        \n        # Validate optimizer\n        supported = ['L_BFGS_B', 'COBYLA']\n        if optimizer_name not in supported:\n            raise ValueError(f\"Unsupported optimizer: {optimizer_name}\")\n        \n        self.energy_history = []\n        self.nfev = 0\n    \n    def callback(self, nfev, params, value, meta):\n        \"\"\"Track convergence history\"\"\"\n        self.energy_history.append(value)\n        self.nfev = nfev\n    \n    def run(self, ansatz, hamiltonian, initial_point=None, seed=None):\n        \"\"\"Run VQE with specified random seed\"\"\"\n        self.energy_history = []\n        self.nfev = 0\n        \n        # Initialize optimizer with COBYLA enhancement\n        if self.optimizer_name == 'L_BFGS_B':\n            optimizer = L_BFGS_B(maxiter=self.maxiter)\n        elif self.optimizer_name == 'COBYLA':\n            # COBYLA needs more iterations (gradient-free)\n            cobyla_maxiter = max(1000, self.maxiter * 10)\n            optimizer = COBYLA(maxiter=cobyla_maxiter)\n        \n        # Generate initial point with seed\n        if initial_point is None and seed is not None:\n            rng = np.random.default_rng(seed)\n            initial_point = rng.uniform(-np.pi, np.pi, ansatz.num_parameters)\n        \n        # Run VQE\n        estimator = Estimator()\n        vqe = VQE(estimator, ansatz, optimizer, callback=self.callback)\n        \n        start_time = time.time()\n        result = vqe.compute_minimum_eigenvalue(hamiltonian, initial_point=initial_point)\n        runtime = time.time() - start_time\n        \n        return {\n            'energy': result.eigenvalue,\n            'optimal_params': result.optimal_parameters,\n            'nfev': self.nfev,\n            'runtime': runtime,\n            'energy_history': self.energy_history.copy(),\n            'seed': seed,\n            'optimizer': self.optimizer_name\n        }\n\ndef run_multistart_vqe(runner, ansatz, hamiltonian, seeds):\n    \"\"\"\n    Run VQE multiple times with different random seeds.\n    \n    Returns:\n    - per_seed: List of individual results\n    - best: Best result across all seeds\n    - Statistics: mean, std, min, max\n    \"\"\"\n    per_seed_results = []\n    \n    for seed in seeds:\n        result = runner.run(ansatz, hamiltonian, seed=seed)\n        per_seed_results.append(result)\n    \n    energies = np.array([r['energy'] for r in per_seed_results])\n    best_idx = int(np.argmin(energies))\n    \n    return {\n        'per_seed': per_seed_results,\n        'best': per_seed_results[best_idx],\n        'best_energy': float(energies[best_idx]),\n        'mean_energy': float(energies.mean()),\n        'std_energy': float(energies.std()),\n        'min_energy': float(energies.min()),\n        'max_energy': float(energies.max()),\n    }\n\nprint(\"✓ VQE runner defined with multi-start support\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Enhanced Plotting with Relative Error %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Plotting Functions\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def plot_multistart_convergence(per_seed_results, exact_energy, ansatz_name, \n",
    "                                optimizer_name, title_suffix=\"\"):\n",
    "    \"\"\"\n",
    "    Plot multi-start VQE convergence with relative error percentage.\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Find best seed\n",
    "    energies = [r['energy'] for r in per_seed_results]\n",
    "    best_idx = int(np.argmin(energies))\n",
    "    \n",
    "    # Collect all histories\n",
    "    all_histories = [r['energy_history'] for r in per_seed_results]\n",
    "    max_len = max(len(h) for h in all_histories)\n",
    "    \n",
    "    # Pad histories\n",
    "    for i, hist in enumerate(all_histories):\n",
    "        if len(hist) < max_len:\n",
    "            all_histories[i] = hist + [hist[-1]] * (max_len - len(hist))\n",
    "    \n",
    "    all_histories = np.array(all_histories)\n",
    "    mean_history = all_histories.mean(axis=0)\n",
    "    std_history = all_histories.std(axis=0)\n",
    "    \n",
    "    iterations = np.arange(max_len)\n",
    "    \n",
    "    # Left plot: Energy convergence\n",
    "    for i, hist in enumerate(all_histories):\n",
    "        if i == best_idx:\n",
    "            continue\n",
    "        ax1.plot(iterations, hist, 'gray', alpha=0.3, linewidth=1)\n",
    "    \n",
    "    ax1.plot(iterations, all_histories[best_idx], 'b-', linewidth=2, label='Best seed')\n",
    "    ax1.plot(iterations, mean_history, 'r--', linewidth=1.5, label='Mean')\n",
    "    ax1.fill_between(iterations, mean_history - std_history, \n",
    "                     mean_history + std_history, color='red', alpha=0.2, label='±1 std')\n",
    "    ax1.axhline(exact_energy, color='green', linestyle='--', linewidth=1.5, label='Exact')\n",
    "    \n",
    "    ax1.set_xlabel('Iteration')\n",
    "    ax1.set_ylabel('Energy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_title(f'{ansatz_name.upper()} + {optimizer_name}')\n",
    "    \n",
    "    # Right plot: Relative error percentage (log scale)\n",
    "    for i, hist in enumerate(all_histories):\n",
    "        rel_err = 100 * np.abs(np.array(hist) - exact_energy) / abs(exact_energy)\n",
    "        rel_err = np.maximum(rel_err, 1e-10)  # Avoid log(0)\n",
    "        if i == best_idx:\n",
    "            continue\n",
    "        ax2.semilogy(iterations, rel_err, 'gray', alpha=0.3, linewidth=1)\n",
    "    \n",
    "    best_rel_err = 100 * np.abs(all_histories[best_idx] - exact_energy) / abs(exact_energy)\n",
    "    best_rel_err = np.maximum(best_rel_err, 1e-10)\n",
    "    ax2.semilogy(iterations, best_rel_err, 'b-', linewidth=2, label='Best seed')\n",
    "    \n",
    "    mean_rel_err = 100 * np.abs(mean_history - exact_energy) / abs(exact_energy)\n",
    "    mean_rel_err = np.maximum(mean_rel_err, 1e-10)\n",
    "    ax2.semilogy(iterations, mean_rel_err, 'r--', linewidth=1.5, label='Mean')\n",
    "    \n",
    "    ax2.set_xlabel('Iteration')\n",
    "    ax2.set_ylabel('Relative Error (%)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3, which='major')\n",
    "    ax2.grid(True, alpha=0.15, which='minor')\n",
    "    \n",
    "    # Enhanced log-scale formatting\n",
    "    ax2.yaxis.set_major_locator(ticker.LogLocator(base=10, numticks=15))\n",
    "    ax2.yaxis.set_minor_locator(ticker.LogLocator(base=10, subs=np.arange(2, 10) * 0.1, numticks=100))\n",
    "    ax2.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: f'{x:.0f}' if x >= 1 else f'{x:.1f}'))\n",
    "    \n",
    "    ax2.set_title(f'Convergence Error{title_suffix}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "print(\"✓ Plotting functions defined with enhanced formatting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Quick Test Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick Test Configuration\n",
    "\n",
    "# === TEST PARAMETERS ===\n",
    "\n",
    "# System size\n",
    "L = 4  # 4 sites = 8 qubits\n",
    "\n",
    "# Minimal parameter space: just 2 points\n",
    "delta_values = [0.0, 0.33]  # Non-dimerized and moderate dimerization\n",
    "U_values = [0.0, 1.0]        # Non-interacting and moderate interaction\n",
    "\n",
    "# Fixed hopping parameter\n",
    "t1 = 1.0\n",
    "\n",
    "# VQE parameters (reduced for speed)\n",
    "ansatz_reps = 2\n",
    "maxiter = 50  # Reduced from 100\n",
    "seeds = [0, 1]  # Just 2 seeds instead of 5\n",
    "optimizers = ['L_BFGS_B', 'COBYLA']  # Skip SLSQP for speed\n",
    "ansatze = ['HVA', 'NP_HVA']  # Skip HEA (we know it performs worst)\n",
    "\n",
    "# Calculate total workload\n",
    "total_points = len(delta_values) * len(U_values)\n",
    "vqe_runs_per_point = len(ansatze) * len(optimizers) * len(seeds)\n",
    "total_vqe_runs = total_points * vqe_runs_per_point\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"QUICK TEST CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"System size: L = {L} ({2*L} qubits)\")\n",
    "print(f\"Dimerization values (δ): {delta_values}\")\n",
    "print(f\"Interaction values (U): {U_values}\")\n",
    "print(f\"Parameter grid: {len(delta_values)} × {len(U_values)} = {total_points} points\")\n",
    "print(f\"\")\n",
    "print(f\"VQE configuration:\")\n",
    "print(f\"  Ansätze: {ansatze}\")\n",
    "print(f\"  Optimizers: {optimizers}\")\n",
    "print(f\"  Seeds: {seeds}\")\n",
    "print(f\"  Max iterations: {maxiter}\")\n",
    "print(f\"  VQE runs per point: {vqe_runs_per_point}\")\n",
    "print(f\"\")\n",
    "print(f\"TOTAL VQE RUNS: {total_vqe_runs}\")\n",
    "print(f\"Estimated time: 2-3 minutes\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run Quick Test\n",
    "\n",
    "This should complete in 2-3 minutes and verify all components work correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Quick Test\n",
    "\n",
    "def delta_to_t2(delta, t1=1.0):\n",
    "    \"\"\"Convert δ to t2: δ = (t1-t2)/(t1+t2)\"\"\"\n",
    "    return t1 * (1 - delta) / (1 + delta)\n",
    "\n",
    "# Storage for results\n",
    "test_results = []\n",
    "test_start_time = time.time()\n",
    "\n",
    "point_idx = 0\n",
    "\n",
    "for delta in delta_values:\n",
    "    t2 = delta_to_t2(delta, t1)\n",
    "    \n",
    "    for U in U_values:\n",
    "        point_idx += 1\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"PARAMETER POINT {point_idx}/{total_points}\")\n",
    "        print(f\"δ = {delta:.3f}, U = {U:.2f} (t1 = {t1:.2f}, t2 = {t2:.3f})\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        point_start = time.time()\n",
    "        \n",
    "        # Build Hamiltonian\n",
    "        H = ssh_hubbard_hamiltonian(L, t1, t2, U, periodic=False)\n",
    "        \n",
    "        # Exact diagonalization\n",
    "        E_exact = exact_diagonalization(H)\n",
    "        print(f\"Exact energy: {E_exact:.6f}\")\n",
    "        \n",
    "        # Run VQE for all ansätze and optimizers\n",
    "        point_results = {\n",
    "            'delta': delta,\n",
    "            'U': U,\n",
    "            't1': t1,\n",
    "            't2': t2,\n",
    "            'exact_energy': E_exact,\n",
    "            'ansatze': {}\n",
    "        }\n",
    "        \n",
    "        N = 2 * L\n",
    "        \n",
    "        for ansatz_name in ansatze:\n",
    "            print(f\"\\n[{ansatz_name}] Running VQE...\")\n",
    "            \n",
    "            # Build ansatz\n",
    "            if ansatz_name == 'HVA':\n",
    "                ansatz = build_ansatz_hva_sshh(L, ansatz_reps, t1, t2, include_U=True)\n",
    "            elif ansatz_name == 'NP_HVA':\n",
    "                ansatz = build_ansatz_np_hva_sshh(L, ansatz_reps)\n",
    "            \n",
    "            point_results['ansatze'][ansatz_name] = {}\n",
    "            \n",
    "            for opt_name in optimizers:\n",
    "                # Run multi-start VQE\n",
    "                runner = VQERunner(maxiter=maxiter, optimizer_name=opt_name)\n",
    "                multistart_result = run_multistart_vqe(runner, ansatz, H, seeds)\n",
    "                \n",
    "                # Calculate relative error\n",
    "                best_energy = multistart_result['best_energy']\n",
    "                rel_error = 100 * abs(best_energy - E_exact) / abs(E_exact)\n",
    "                \n",
    "                print(f\"  {opt_name}: {best_energy:.6f} ({rel_error:.2f}% error)\")\n",
    "                \n",
    "                point_results['ansatze'][ansatz_name][opt_name] = multistart_result\n",
    "                \n",
    "                # Generate convergence plot\n",
    "                fig = plot_multistart_convergence(\n",
    "                    multistart_result['per_seed'],\n",
    "                    E_exact,\n",
    "                    ansatz_name,\n",
    "                    opt_name,\n",
    "                    title_suffix=f\" (δ={delta:.2f}, U={U:.1f})\"\n",
    "                )\n",
    "                plt.show()\n",
    "                plt.close(fig)\n",
    "        \n",
    "        point_time = time.time() - point_start\n",
    "        elapsed = time.time() - test_start_time\n",
    "        \n",
    "        test_results.append(point_results)\n",
    "        \n",
    "        print(f\"\\n✓ Point {point_idx}/{total_points} complete in {point_time:.1f}s\")\n",
    "        print(f\"Progress: {100*point_idx/total_points:.1f}%\")\n",
    "        print(f\"Elapsed: {elapsed:.1f}s\")\n",
    "\n",
    "total_time = time.time() - test_start_time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"QUICK TEST COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total runtime: {total_time:.1f} seconds ({total_time/60:.2f} minutes)\")\n",
    "print(f\"Total VQE runs: {total_vqe_runs}\")\n",
    "print(f\"Average time per point: {total_time/total_points:.1f} seconds\")\n",
    "print(f\"Average time per VQE run: {total_time/total_vqe_runs:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Summary Table\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for result in test_results:\n",
    "    delta = result['delta']\n",
    "    U = result['U']\n",
    "    exact = result['exact_energy']\n",
    "    \n",
    "    print(f\"\\n[δ={delta:.2f}, U={U:.1f}] Exact: {exact:.6f}\")\n",
    "    print(f\"{'Ansatz':<10} {'Optimizer':<12} {'Best Energy':<14} {'Rel Error %':<12}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for ansatz_name, ansatz_data in result['ansatze'].items():\n",
    "        for opt_name, opt_data in ansatz_data.items():\n",
    "            best_energy = opt_data['best_energy']\n",
    "            rel_error = 100 * abs(best_energy - exact) / abs(exact)\n",
    "            print(f\"{ansatz_name:<10} {opt_name:<12} {best_energy:<14.6f} {rel_error:<12.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✓ Quick test completed successfully!\")\n",
    "print(\"All components working correctly - ready for full sweep on Colab\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This quick test notebook verifies:\n",
    "\n",
    "✅ **Hamiltonian construction** - Jordan-Wigner transformation working  \n",
    "✅ **Ansatz building** - HVA and NP_HVA circuits generated correctly  \n",
    "✅ **VQE runner** - COBYLA gets 10× iterations, convergence tracking works  \n",
    "✅ **Multi-start** - Multiple random seeds tested, statistics computed  \n",
    "✅ **Plotting** - Relative error % plots with enhanced formatting  \n",
    "✅ **No runtime errors** - All imports and dependencies working  \n",
    "\n",
    "**Expected Performance** (based on previous runs):\n",
    "- HVA should achieve ~0-1% error for U=0.0 (non-interacting)\n",
    "- NP_HVA should achieve ~3-7% error for U=1.0 (interacting)\n",
    "- COBYLA may need more iterations but should converge\n",
    "\n",
    "**Next Steps**:\n",
    "1. If this test passes → Run full sweep on Google Colab\n",
    "2. If issues found → Debug before attempting full sweep\n",
    "\n",
    "---\n",
    "\n",
    "**Repository**: https://github.com/morris-c-hsu/VqeTests  \n",
    "**Branch**: `claude/read-this-r-01DLdEcvW8hustGKsyPjZzLM`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}